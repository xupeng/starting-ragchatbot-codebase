from google import genai
from google.genai import types
from typing import List, Optional, Dict, Any, Callable, Union
import logging
import os


class OfficialGeminiGenerator:
    """ä½¿ç”¨å®˜æ–¹Google Gemini APIçš„AIç”Ÿæˆå™¨"""
    
    def __init__(self, api_key: str, model: str):
        # éªŒè¯è¾“å…¥å‚æ•°
        if not api_key or api_key.strip() == "":
            raise ValueError("API Key ä¸èƒ½ä¸ºç©ºã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GEMINI_API_KEY")
        
        if not model or model.strip() == "":
            raise ValueError("Model ä¸èƒ½ä¸ºç©ºã€‚è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® GEMINI_MODEL")
        
        # è®¾ç½®æ—¥å¿—
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–å®˜æ–¹Geminiå®¢æˆ·ç«¯
        try:
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå®˜æ–¹SDKä¼šè‡ªåŠ¨è¯»å–ï¼‰
            os.environ['GEMINI_API_KEY'] = api_key.strip()
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            self.client = genai.Client()
            self.model = model.strip()
            
            self.logger.info(f"å®˜æ–¹Gemini AIç”Ÿæˆå™¨åˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: {self.model}")
            
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–å®˜æ–¹Geminiå®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise ValueError(f"æ— æ³•åˆå§‹åŒ–å®˜æ–¹Geminiå®¢æˆ·ç«¯: {e}")
    
    def generate_response(self, query: str,
                         conversation_history: Optional[str] = None,
                         tools: Optional[Union[Callable, List[Callable]]] = None) -> str:
        """
        ä½¿ç”¨å®˜æ–¹Gemini APIç”Ÿæˆå“åº”ï¼Œæ”¯æŒè‡ªåŠ¨å‡½æ•°è°ƒç”¨
        
        Args:
            query: ç”¨æˆ·çš„é—®é¢˜æˆ–è¯·æ±‚
            conversation_history: ä¹‹å‰çš„å¯¹è¯å†å²
            tools: å¯ç”¨çš„å·¥å…·å‡½æ•°ï¼Œå¯ä»¥æ˜¯å•ä¸ªå‡½æ•°æˆ–å‡½æ•°åˆ—è¡¨
            
        Returns:
            ç”Ÿæˆçš„å“åº”æ–‡æœ¬
        """
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯¾ç¨‹ææ–™åŠ©æ‰‹ã€‚ä½ æœ‰ä¸¤ä¸ªä¸»è¦å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·ï¼š

1. search_course_content - ç”¨äºæœç´¢è¯¾ç¨‹å†…å®¹ã€ç« èŠ‚è¯¦æƒ…ç­‰
2. get_course_outline - ç”¨äºè·å–å®Œæ•´çš„è¯¾ç¨‹å¤§çº²ä¿¡æ¯

é‡è¦æŒ‡å¯¼åŸåˆ™ï¼š
- å¯¹äºè¯¾ç¨‹å¤§çº²ç›¸å…³é—®é¢˜ï¼ˆå¦‚"è¯¾ç¨‹å¤§çº²"ã€"è¯¾ç¨‹ç»“æ„"ã€"æœ‰å“ªäº›è¯¾ç¨‹"ã€"è¯¾ç¨‹åŒ…å«ä»€ä¹ˆå†…å®¹"ï¼‰ï¼Œä½¿ç”¨ get_course_outline å‡½æ•°
- å¯¹äºå…·ä½“è¯¾ç¨‹å†…å®¹é—®é¢˜ï¼ˆå¦‚ç‰¹å®šç« èŠ‚å†…å®¹ã€æŠ€æœ¯ç»†èŠ‚ç­‰ï¼‰ï¼Œä½¿ç”¨ search_course_content å‡½æ•°
- è¯¾ç¨‹å¤§çº²æŸ¥è¯¢åº”è¿”å›ï¼šè¯¾ç¨‹æ ‡é¢˜ã€è¯¾ç¨‹é“¾æ¥ã€æ•™å¸ˆä¿¡æ¯ã€å®Œæ•´çš„è¯¾ç¨‹åˆ—è¡¨ï¼ˆè¯¾ç¨‹ç¼–å·å’Œæ ‡é¢˜ï¼‰
- åŸºäºæœç´¢ç»“æœæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”
- ä¿æŒå›ç­”ç®€æ´æ˜äº†
- å¯¹äºä¸€èˆ¬å¯¹è¯ï¼ˆå¦‚é—®å€™ï¼‰ï¼Œç›´æ¥å›ç­”å³å¯

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜é€‰æ‹©åˆé€‚çš„å·¥å…·å¹¶æä¾›å¸®åŠ©ã€‚"""
        
        # æ„å»ºå†…å®¹
        full_prompt = system_prompt
        if conversation_history:
            full_prompt += f"\n\nå†å²å¯¹è¯:\n{conversation_history}"
        full_prompt += f"\n\nç”¨æˆ·é—®é¢˜: {query}"
        
        contents = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=full_prompt)]
            )
        ]
        
        # é…ç½®ç”Ÿæˆå‚æ•°
        config_kwargs = {}
        if tools:
            # å¤„ç†å·¥å…·å‚æ•° - æ”¯æŒå•ä¸ªå‡½æ•°æˆ–å‡½æ•°åˆ—è¡¨
            if callable(tools):
                # å•ä¸ªå‡½æ•°
                config_kwargs["tools"] = [tools]
            elif isinstance(tools, (list, tuple)):
                # å‡½æ•°åˆ—è¡¨
                config_kwargs["tools"] = list(tools)
            else:
                # å…¶ä»–æƒ…å†µï¼Œå°è¯•è½¬æ¢ä¸ºåˆ—è¡¨
                config_kwargs["tools"] = [tools]
        
        config = types.GenerateContentConfig(**config_kwargs)
        
        # å‘é€APIè¯·æ±‚
        try:
            self.logger.info(f"ğŸš€ å‘é€å®˜æ–¹Gemini APIè¯·æ±‚")
            self.logger.info(f"   æ¨¡å‹: {self.model}")
            
            if tools:
                if callable(tools):
                    self.logger.info(f"   åŒ…å«å·¥å…·: {tools.__name__}")
                elif isinstance(tools, (list, tuple)):
                    tool_names = [f.__name__ if callable(f) else str(f) for f in tools]
                    self.logger.info(f"   åŒ…å«å·¥å…·: {', '.join(tool_names)}")
                else:
                    self.logger.info(f"   åŒ…å«å·¥å…·: {tools}")
            
            # è®°å½•æŸ¥è¯¢é¢„è§ˆ
            query_preview = query[:100] if len(query) > 100 else query
            self.logger.info(f"   ç”¨æˆ·æŸ¥è¯¢: {query_preview}...")
            
            # è°ƒç”¨å®˜æ–¹API
            response = self.client.models.generate_content(
                model=self.model,
                contents=contents,
                config=config
            )
            
            self.logger.info(f"âœ… æˆåŠŸæ”¶åˆ°å®˜æ–¹Gemini APIå“åº”")
            
            # è·å–å“åº”æ–‡æœ¬
            response_text = response.text if response.text else ""
            
            self.logger.info(f"   å“åº”é•¿åº¦: {len(response_text)} å­—ç¬¦")
            
            return response_text
            
        except Exception as e:
            # è¯¦ç»†é”™è¯¯æ—¥å¿—
            error_msg = f"å®˜æ–¹Gemini APIè¯·æ±‚å¤±è´¥: {str(e)}"
            self.logger.error(f"âŒ {error_msg}")
            self.logger.error(f"   å¼‚å¸¸ç±»å‹: {type(e).__name__}")
            
            # å¸¸è§é”™è¯¯æç¤º
            if "API_KEY" in str(e) or "authentication" in str(e).lower():
                error_msg += "\nğŸ’¡ è¯·æ£€æŸ¥GEMINI_API_KEYæ˜¯å¦æ­£ç¡®è®¾ç½®"
                error_msg += "\nğŸ’¡ è·å–APIå¯†é’¥: https://aistudio.google.com/app/apikey"
            elif "quota" in str(e).lower() or "limit" in str(e).lower():
                error_msg += "\nğŸ’¡ å¯èƒ½çš„åŸå› : APIé…é¢ä¸è¶³æˆ–è¯·æ±‚é¢‘ç‡é™åˆ¶"
            elif "network" in str(e).lower() or "connection" in str(e).lower():
                error_msg += "\nğŸ’¡ å¯èƒ½çš„åŸå› : ç½‘ç»œè¿æ¥é—®é¢˜"
            
            raise RuntimeError(error_msg)